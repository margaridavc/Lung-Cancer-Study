{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f726fa86fffdd98c",
   "metadata": {},
   "source": [
    "# Lung Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Index <a id=\"Index\"></a>\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "    1. [Project Overview](#Project-Overview)\n",
    "    2. [Objectives](#Objectives)\n",
    "    3. [Our Approach](#Our-Approach)\n",
    "2. [Imports](#Imports)\n",
    "3. [Obtaining the features](#Obtain-the-features)\n",
    "4. [Data Clean-up](#Data-Clean-up)\n",
    "5. [Data Analysis](#Data-Analysis)\n",
    "6. [Classification](#Classification)\n",
    "    1. [Decision Tree Classifier](#Decision-Tree-Classifier)\n",
    "    2. [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "    3. [Gradient Boosting Classifier](#Gradient-Boosting-Classifier)\n",
    "    4. [K Neighbors Classifier](#Knn)\n",
    "    5. [Support Vector Machines](#Support-Vector-Machines)\n",
    "    6. [Naive Bayes](#Naive-Bayes)\n",
    "        1. [GaussianNB](#GaussianNB)\n",
    "        2. [MultinomialNB](#MultinomialNB)\n",
    "7. [Conclusion](#Conclusion)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62d0710a27391587"
  },
  {
   "cell_type": "markdown",
   "id": "b3e8ef7050497e56",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"Introduction\"></a>\n",
    "[Back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Project Overview <a id=\"Project-Overview\"></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5da9eb677675b80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this project our goal is to develop a  Data Science-based solution to solve the problem of Lung Cancer\n",
    "Classification using Computerized Tomography (CT) Data. Our initial data comes from images of CT scans from 1010 patients and we intend to extract its features from the images."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a5c089d3f0cab1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Objectives <a id=\"Objectives\"></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18a3e94858f18469"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our goal is to develop a robust and accurate classification system that can distinguish between benign and malignant nodules, which could assist healthcare professionals in making informed decisions, as well as improve our programming skills and machine learning and data science knowledge."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb4310d0d3e29b49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Our Approach <a id=\"Our-Approach\"></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db2fc6ac6f1dfe2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step is to extract the features from the CT images and colect them in a csv.\n",
    "Next we will evaluate the need for cleaning the data and preprocess it.\n",
    "After that, the final step is to develop machine learning models and avaluate its performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "748f84bc0a2db117"
  },
  {
   "cell_type": "markdown",
   "id": "338499ee5171f96a",
   "metadata": {},
   "source": [
    "## Imports\n",
    "[Back to index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b6ef6d8da5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2dc2891fdbaa4",
   "metadata": {},
   "source": [
    "### Obtaining the features <a id=\"Obtain-the-features\"></a>\n",
    "[Back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61600a8",
   "metadata": {},
   "source": [
    "Running the python script:\n",
    "\n",
    "`python get_features.py`\n",
    " \n",
    "we are going to acess the information in the pylidc library and extract its features and calculating the mean or mode for all annotators as well as extracting all radiomics features"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "%run get_features.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25df58ad1ffc61be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To run the script change the cell above from markdown to code and run it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2176ef8262197b87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you interrupt the cell above without it finishing you need to restart your kerner to prevent: \n",
    "\n",
    "`PendingRollbackError: Can't reconnect until invalid transaction is rolled back.  Please rollback() fully before proceeding (Background on this error at: https://sqlalche.me/e/20/8s2b)`\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b840754ffb311e45"
  },
  {
   "cell_type": "markdown",
   "id": "23eea0d1c2b7cad1",
   "metadata": {},
   "source": [
    "## Data Clean-up <a id=\"Data-Clean-up\"></a>\n",
    "[Back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are going to clean the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4bea07121e607e7"
  },
  {
   "cell_type": "markdown",
   "id": "82d53b77",
   "metadata": {},
   "source": [
    "For starters let's read the csv and print the features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('radiomic_features.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e0a2b",
   "metadata": {},
   "source": [
    "Next, we are going to check if there are any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaa4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since there are no null values we don't need to perform any null value handling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef7c6ccdd31ebf6"
  },
  {
   "cell_type": "markdown",
   "id": "35302b5a",
   "metadata": {},
   "source": [
    "Now we are going to check if there are columns with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6071ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A lot of columns have only one value, and we can conclude that they will not be helpful at predicting the label. So, we are going to drop them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22ddc15c9588bd41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_value_counts = df.nunique()\n",
    "columns_with_single_unique_value = unique_value_counts[unique_value_counts == 1].index\n",
    "df.drop(columns=columns_with_single_unique_value,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the updated dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "910b3954ec0a31d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5a7cdbf30b1fb8f"
  },
  {
   "cell_type": "markdown",
   "id": "c892bd01",
   "metadata": {},
   "source": [
    "As we can see, in the dataset some columns have Ids and tuples with numbers and since there is no point in label encoding them since these columns donÂ´t really represent features of the nodules and just information about the general images or masks. So, we will drop those columns, remaining just numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb10130994b97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(include=[int, float])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f347093",
   "metadata": {},
   "source": [
    "Since we applied the mean to all of the values in the annotations for each nodule they are in between [1,5]. We are going to check the count of each value in the malignancy column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"malignancy\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d52679148ec2e98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, there are a lot of values with 3, so we are going to drop them since they are not useful for our classification.\n",
    "The rest of the values are going to be converted to 0 or 1, where 0 is benign and 1 is malignant."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88844ba8f3cd8d89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[df['malignancy'] != 3]\n",
    "\n",
    "df.loc[:, \"malignancy\"] = df[\"malignancy\"].apply(lambda x: 1 if x > 3 else 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65fac7b0be7f0bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the updated malignancy column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b78de9a902c0414"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"malignancy\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "638089bc7df483a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As shown above, the labels are not balanced, so we are going to use oversampling to balance them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a01882f287d6bf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "df, _ = smote.fit_resample(df, df['malignancy'])"
   ],
   "metadata": {},
   "id": "ed43086d7b9978d5"
  },
  {
   "cell_type": "markdown",
   "id": "76b7dd2c",
   "metadata": {},
   "source": [
    "Now the values should be equally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"malignancy\"].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d4919d09c8d37b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afterwards we need to normalize the columns using Min-Max scaling due to not having scale consistency"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cbeb93e4fc183f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185a0103aed89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df - df.min()) / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the column names are very long and not concise nor clear we will simplify them to make them more understandable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6201c49fa9c7fa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_column_names = [\n",
    "    'Mean',\n",
    "    'VoxelNum',\n",
    "    'VolumeNum',\n",
    "    'Elongation',\n",
    "    'Flatness',\n",
    "    'LeastAxisLength',\n",
    "    'MajorAxisLength',\n",
    "    'DiameterColumn',\n",
    "    'DiameterRow',\n",
    "    'DiameterSlice',\n",
    "    'Max3DDiameter',\n",
    "    'MeshVolume',\n",
    "    'MinorAxisLength',\n",
    "    'Sphericity',\n",
    "    'SurfaceArea',\n",
    "    'SurfaceVolRatio',\n",
    "    'VoxelVol',\n",
    "    'Energy',\n",
    "    'TotalEnergy',\n",
    "    'DiffEntropy',\n",
    "    'JointEntropy',\n",
    "    'SumEntropy',\n",
    "    'DependEntropy',\n",
    "    'DependNonUniformity',\n",
    "    'DependNonUniformityNorm',\n",
    "    'DependVariance',\n",
    "    'GrayLevelNonUniformity',\n",
    "    'LargeDependEmphasis',\n",
    "    'LargeDependHighGLEmphasis',\n",
    "    'LargeDependLowGLEmphasis',\n",
    "    'SmallDependEmphasis',\n",
    "    'SmallDependHighGLEmphasis',\n",
    "    'SmallDependLowGLEmphasis',\n",
    "    'GLNonUniformity',\n",
    "    'LongRunEmphasis',\n",
    "    'LongRunHighGLEmphasis',\n",
    "    'LongRunLowGLEmphasis',\n",
    "    'RunEntropy',\n",
    "    'RunLengthNonUniformity',\n",
    "    'RunLenNonUniformityNorm',\n",
    "    'RunPercentage',\n",
    "    'RunVariance',\n",
    "    'ShortRunEmphasis',\n",
    "    'ShortRunHighGLEmphasis',\n",
    "    'ShortRunLowGLEmphasis',\n",
    "    'GLNonUniformity_GLSZM',\n",
    "    'LargeAreaEmphasis',\n",
    "    'LargeAreaHighGLEmphasis',\n",
    "    'LargeAreaLowGLEmphasis',\n",
    "    'SizeZoneNonUniformity',\n",
    "    'SizeZoneNonUniformityNorm',\n",
    "    'SmallAreaEmphasis',\n",
    "    'SmallAreaHighGLEmphasis',\n",
    "    'SmallAreaLowGLEmphasis',\n",
    "    'ZoneEntropy',\n",
    "    'ZonePercentage',\n",
    "    'ZoneVariance',\n",
    "    'Subtlety',\n",
    "    'InternalStructure',\n",
    "    'Sphericity',\n",
    "    'Margin',\n",
    "    'Lobulation',\n",
    "    'Spiculation',\n",
    "    'Texture',\n",
    "    'Malignancy'\n",
    "]\n",
    "df.columns = new_column_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45748fe16bdfb7ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's take a look at the updated dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b68c635906cf648"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260e74c684bee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d435d1b5f271c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T18:18:20.450713Z",
     "start_time": "2023-11-04T18:18:07.486632Z"
    }
   },
   "source": [
    "## Data Analysis <a id=\"Data-Analysis\"></a>\n",
    "[Back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rigth now we are going to analyze the data and see if there are any correlations between the features and the label in order to have better performance in the our classification models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28bcf2cc93f5e3e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beb8d633bc01273d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['object'])\n",
    "numeric_columns = df.select_dtypes(include=['object'])\n",
    "correlation_matrix = numeric_columns.corr()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c8d1961e771d802"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code provides insights into the distribution and characteristics of these diagnostic values, wich may represent various image and mask features "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eefb819e4eb2b2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Diagnostics Columns\n",
    "mean_image = df['Mean']\n",
    "voxel_num = df['VoxelNum']\n",
    "volume_num = df['VolumeNum']\n",
    "\n",
    "# Summary statistics\n",
    "print(mean_image.describe())\n",
    "print(voxel_num.describe())\n",
    "print(volume_num.describe())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7caa6b650e2a38ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code segment focuses on a set of columns related to shape features of tumors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e82edc0bf6620aab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shape features\n",
    "shape_columns = [\n",
    "    'Elongation',\n",
    "    'Flatness',\n",
    "    'LeastAxisLength',\n",
    "    'MajorAxisLength',\n",
    "    'DiameterColumn',\n",
    "    'DiameterRow',\n",
    "    'DiameterSlice',\n",
    "    'Max3DDiameter',\n",
    "    'MeshVolume',\n",
    "    'MinorAxisLength',\n",
    "    'Sphericity',\n",
    "    'SurfaceArea',\n",
    "    'SurfaceVolRatio',\n",
    "    'VoxelVol',\n",
    "]\n",
    "\n",
    "# Summary statistics for shape features\n",
    "shape_summary = df[shape_columns].describe()\n",
    "print(shape_summary)\n",
    "\n",
    "# Correlation analysis for shape features\n",
    "shape_correlation_matrix = df[shape_columns].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(shape_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix for Shape Features\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5181f41f8a939a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the correlation matrix displayed above, we observe a rich network of interconnections among various features. Notably, a prominent 5x5 square region stands out, marked in pink, indicating a substantial degree of correlation between the enclosed features. In practical terms, this means that when one feature experiences an increase, a corresponding increase in the other is highly likely, signifying a strong positive correlation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99b587729c34579c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GLSZM Features\n",
    "glszm_columns = [\n",
    "    'GLNonUniformity_GLSZM',\n",
    "    'LargeAreaEmphasis',\n",
    "    'LargeAreaHighGLEmphasis',\n",
    "    'LargeAreaLowGLEmphasis',\n",
    "    'SizeZoneNonUniformity',\n",
    "    'SizeZoneNonUniformityNorm',\n",
    "    'SmallAreaEmphasis',\n",
    "    'SmallAreaHighGLEmphasis',\n",
    "    'SmallAreaLowGLEmphasis',\n",
    "    'ZoneEntropy',\n",
    "    'ZonePercentage',\n",
    "    'ZoneVariance',\n",
    "]\n",
    "\n",
    "# Summary statistics for GLSZM features\n",
    "glszm_summary = df[glszm_columns].describe()\n",
    "print(glszm_summary)\n",
    "\n",
    "# Correlation analysis for GLSZM features\n",
    "glszm_correlation_matrix = df[glszm_columns].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(glszm_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix for GLSZM Features\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66500ad174b60cd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Gray-Level Size Zone Matrix (GLSZM) is a quantitative image analysis technique used to characterize the spatial distribution of zones of specific gray levels within an image. It provides information about the frequency and sizes of these zones, offering insights into the textural properties of the image. In simpler terms, the GLSZM helps us understand how different shades of gray are arranged in the image and how large or small these regions of specific gray levels are.\n",
    "\n",
    "In our analysis, we've observed that there are a lot of features that have a strong correlation (value = 1); with this information we conclude that a lor of the features are redundant and in the furture could be removed. However in this project we are going to keep all the features seen above and see how they perform in our classification models. In theory, our conclusion will be that they not affect the performance of the models.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b077ee0bbe7fee8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rigth now we are going to analyze the correlation between the features and the malignancy label."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e08b3a621b32c9c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_threshold = 0.35\n",
    "\n",
    "correlation_with_malignancy = df.corr()['Malignancy']\n",
    "high_correlation_features = correlation_with_malignancy[correlation_with_malignancy.abs() >= correlation_threshold].index\n",
    "print(high_correlation_features)\n",
    "\n",
    "# Create a bar plot to visualize correlations\n",
    "plt.figure(figsize=(15, 9))\n",
    "sns.barplot(x=correlation_with_malignancy.index, y=correlation_with_malignancy)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Correlation with Malignancy')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdd2a6b330802c05"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c456834c23693982"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, there are some features that have a high correlation with the label, so we are going to use them in our classification models to see how it performs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfb6dd75f1783628"
  },
  {
   "cell_type": "markdown",
   "id": "ccb9048aafe9ceba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-04T18:19:38.800509Z"
    }
   },
   "source": [
    "## Classification <a id=\"Classification\"></a>\n",
    "[Back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We created some functions to help us test every model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "defd5bc55f31ce48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def heatmap(test,pred):\n",
    "    cm = confusion_matrix(test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c47166e5a97efe5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d08d11609f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(test,pred):\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    report = classification_report(test, pred, zero_division=1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    heatmap(test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cross_validation(model, a, b, cv=10):\n",
    "    scores = cross_val_score(model, a, b, cv=cv, scoring='accuracy')\n",
    "    plt.figure(figsize=(8, 4))  # Create a separate figure\n",
    "    plt.hist(scores)\n",
    "    plt.title('Cross Validation average score: {}'.format(np.average(scores)))\n",
    "    plt.show()\n",
    "    return np.average(scores)  # Return the average accuracy score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e73c27daa2850834"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def average_score(model, a, b):\n",
    "    model_accuracies = []\n",
    "    model_precisions = []\n",
    "    for repetition in range(100):\n",
    "        x_train, x_test, Y_train, Y_test = train_test_split(a, b, test_size=0.3)\n",
    "\n",
    "        model.fit(x_train, Y_train)\n",
    "        Y_pred = model.predict(x_test)\n",
    "\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        precision = precision_score(Y_test, Y_pred)\n",
    "\n",
    "        model_accuracies.append(accuracy)\n",
    "        model_precisions.append(precision)\n",
    "        \n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))  # Create two subplots\n",
    "\n",
    "    ax1.hist(model_accuracies, color='blue', alpha=0.7, label='Accuracy')\n",
    "    ax1.set_title('Accuracy average score: {}'.format(np.average(model_accuracies)))\n",
    "\n",
    "    ax2.hist(model_precisions, color='green', alpha=0.7, label='Precision')\n",
    "    ax2.set_title('Precision average score: {}'.format(np.average(model_precisions)))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    average_accuracy = np.average(model_accuracies)\n",
    "    average_precision = np.average(model_precisions)\n",
    "\n",
    "    return average_accuracy, average_precision\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c31b3d4ce74a397"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def importance(model, a):\n",
    "    impor=pd.DataFrame({'feature':a.columns,\n",
    "                             'importance':np.round(model.feature_importances_, 3)})\n",
    "    impor.sort_values('importance',ascending=False, inplace =True)\n",
    "    return impor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "807b1234260cd375"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After noticing that there are higher correlation features than other, we did a test with the Random Forest Classifier: we tried only using the features with 0.5 correlation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84011d227a053e65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_df = df[high_correlation_features]\n",
    "testing_X = df.iloc[:, :-1]\n",
    "testing_y = df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(testing_X, testing_y, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71768b5acb95c94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_rf_classifier = RandomForestClassifier(criterion=\"entropy\", max_depth=30, min_samples_leaf=2, n_estimators=200)\n",
    "testing_rf_classifier.fit(X_train, y_train)\n",
    "y_pred = testing_rf_classifier.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72ac5870c28caab6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15b36074c38c9000"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "average_score(testing_rf_classifier, testing_X, testing_y)\n",
    "cross_validation(testing_rf_classifier, testing_X, testing_y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8332d04175858e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "After noticing that diference in the percentages isn't significant, we decided to keep all the features.\n",
    " \n",
    "We tried with 0.35 and 0.5 correlation values and the results were the same."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "424790d159ed3c87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are going to test the models and see which one performs better. With each model we are going to test its accuracy, precision and cross validation score. While doint it, we are going to save each models test and then compare it after, to see which one performs better.\n",
    "\n",
    "For the models hyper-paramenters we used the default ones first. Then after completing all the code for all the models we did some parameter tuning and we verified that the change was almost not significant, still, we used the best parameters for each model.\n",
    " \n",
    "The code for the parameter tuning is in the end of the notebook.\n",
    "\n",
    "On the models that permit it, we show the importance of each feature."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43847560e64d5762"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_scores = []\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = df.iloc[:, -1]   # Target (the last column)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2988673cef649efa"
  },
  {
   "cell_type": "markdown",
   "id": "c56c480d32daab7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:16:19.563786Z",
     "start_time": "2023-11-05T14:16:19.481481Z"
    }
   },
   "source": [
    "### Decision Tree Classifier <a id=\"Decision-Tree-Classifier\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=1, min_samples_split=10) \n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e11ab12afae43afd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b29cd5100404e348"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_accuracy,tree_precision = average_score(tree,X,y)\n",
    "tree_cross = cross_validation(tree,X,y)\n",
    "model_scores.append((\"Decision Tree Classifier\",tree_accuracy,tree_precision,tree_cross))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfc4d2e2f05bdbc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance(tree,X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdd279d028fdb104"
  },
  {
   "cell_type": "markdown",
   "id": "fb456e8c672b88e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:49:32.479574Z",
     "start_time": "2023-11-05T14:49:25.215538Z"
    }
   },
   "source": [
    "### Random Forest Classifier <a id=\"Random-Forest-Classifier\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6012f5a49955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(criterion=\"entropy\", max_depth=30, min_samples_leaf=2, n_estimators=200)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a453ee8db8b245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_accuracy, rf_precision = average_score(rf_classifier,X,y)\n",
    "rf_cross = cross_validation(rf_classifier,X,y)\n",
    "model_scores.append((\"Random Forest Classifier\",rf_accuracy,rf_precision,rf_cross))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f93c5c23afd5f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance(rf_classifier,X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "348964806eb2e0b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier <a id=\"Gradient-Boosting-Classifier\"></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fe07f5e4bd843cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_depth=6)\n",
    "GB.fit(X_train, y_train)\n",
    "y_pred = GB.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8ba145fb180fee0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce5fe730ed8d7fa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gb_accuracy, gb_precision = average_score(GB,X,y)\n",
    "gb_cross = cross_validation(GB,X,y)\n",
    "model_scores.append((\"Gradient Boosting Classifier\",gb_accuracy, gb_precision,gb_cross))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbede081147968e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance(GB,X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced3d1fb061d682b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Neighbors Classifier <a id=\"Knn\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T14:20:39.627947Z",
     "start_time": "2023-11-05T14:20:39.605186Z"
    }
   },
   "id": "eaffbba44eb6dd4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing to see which number of neighbors is the best"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a8cc2a167b1b626"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(np.array(X_test))\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "best_score = (1, score)\n",
    "for i in range(2, 101):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(np.array(X_test))\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > best_score[1]:  # Compare with the accuracy score, not the tuple\n",
    "        best_score = (i, score)\n",
    "\n",
    "print(\"Best accuracy is \" + str(best_score[1]) + \" with \" + str(best_score[0]) + \" neighbors\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1abf2425ce0a192b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_score[0])\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(np.array(X_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4357f0acf78a03cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec84f50e57f5bf8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "average_score(knn,np.array(X),y)\n",
    "cross_validation(knn,np.array(X),y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9ac5cd8862ea07"
  },
  {
   "cell_type": "markdown",
   "id": "7789853ad2d1c37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:20:41.005159Z",
     "start_time": "2023-11-05T14:20:40.975948Z"
    }
   },
   "source": [
    "### Support Vector Machines <a id=\"Support-Vector-Machines\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847546be00ee57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(C=10, gamma='scale', kernel='rbf')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc27bd88e0d9591c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_accuracy, svm_precision = average_score(svclassifier,X,y)\n",
    "svm_cross = cross_validation(svclassifier,X,y)\n",
    "model_scores.append((\"Support Vector Machines\",svm_accuracy, svm_precision,svm_cross))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa773268049d3d05"
  },
  {
   "cell_type": "markdown",
   "id": "ebcc7db0f6dce706",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-04T18:19:38.812015Z"
    }
   },
   "source": [
    "### Naive Bayes <a id=\"Naive-Bayes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ec0a4a4ad4766",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "### GaussianNB <a id=\"GaussianNB\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f7961653ea819",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianNB()\n",
    "gauss.fit(X_train, y_train)\n",
    "y_pred = gauss.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b4701616789f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gnb_accuracy, gnb_precision = average_score(gauss,X,y)\n",
    "gnb_cross = cross_validation(gauss,X,y)\n",
    "model_scores.append((\"Gaussian Naive Bayes\",gnb_accuracy, gnb_precision,gnb_cross))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874d06b7eda6eb09"
  },
  {
   "cell_type": "markdown",
   "id": "42bb091b927d11d3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-04T18:19:38.814552Z"
    }
   },
   "source": [
    "### MultinomialNB <a id=\"MultinomialNB\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822ad13100866bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = MultinomialNB(alpha=0.5)\n",
    "mult.fit(X_train, y_train)\n",
    "y_pred = mult.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65220e83f95ba2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a635cc48da6186",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnb_accuracy, mnb_precision = average_score(mult,X,y)\n",
    "mnb_cross = cross_validation(mult,X,y)\n",
    "model_scores.append((\"Multinomial Naive Bayes\",mnb_accuracy, mnb_precision,mnb_cross))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparing the models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ea36613191b5bc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we compare all the models test scores:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c2a7ec1bb566a67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_names, accuracies, precisions, cross_scores = zip(*model_scores)\n",
    "\n",
    "x = np.arange(len(model_names))  # X-axis positions\n",
    "\n",
    "bar_width = 0.3  # Increased bar width\n",
    "bar_positions = np.arange(len(model_names))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.bar(bar_positions - bar_width, accuracies, width=bar_width, label='Accuracy', color='b', alpha=0.7)\n",
    "plt.bar(bar_positions, precisions, width=bar_width, label='Precision', color='g', alpha=0.7)\n",
    "plt.bar(bar_positions + bar_width, cross_scores, width=bar_width, label='Cross-Validation', color='r', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Model Comparison')\n",
    "plt.legend()\n",
    "plt.xticks(bar_positions, model_names, rotation=45)\n",
    "\n",
    "# Adding text labels for the actual percentages with separation\n",
    "for i in range(len(model_names)):\n",
    "    plt.text(bar_positions[i] - bar_width, accuracies[i] + 0.02, f'{accuracies[i]:.2%}', ha='center')\n",
    "    plt.text(bar_positions[i], precisions[i] + 0.02, f'{precisions[i]:.2%}', ha='center')\n",
    "    plt.text(bar_positions[i] + bar_width, cross_scores[i] + 0.02, f'{cross_scores[i]:.2%}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "959d657e0d6541c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameter Tuning <a id=\"Parameter-Tuning\"></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb57c8966840ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are the parameter grids for the models to see which parameters are the best for each model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c947d3ba1fe4722d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid_decision_tree = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d1e42a77553a094"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid_random_forest = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cb73a15cf664cb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid_gradient_boost = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 4, 5, 6]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0e9f03b820b681b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the K Neighbors Classifier we are going to use the best number of neighbors we found before."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3f18aae11faf5ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ffb1d825dba8e47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the Naive Bayes models there are no hyperparameters to tune for Gaussian."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a5b11e5e5d49c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid_multinomial_nb = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e51488831b9da1d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boost': GradientBoostingClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Decision Tree': param_grid_decision_tree,\n",
    "    'Random Forest': param_grid_random_forest,\n",
    "    'Gradient Boost': param_grid_gradient_boost,\n",
    "    'SVC': param_grid_svc,\n",
    "    'Gaussian Naive Bayes': {},  # No hyperparameters for Gaussian Naive Bayes\n",
    "    'Multinomial Naive Bayes': param_grid_multinomial_nb\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ea46359e909e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_best_model_parameters(classifier, parameters_grid, a, b):\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=parameters_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(a, b)\n",
    "\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c2aafe654d16e6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params_and_scores = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    if not param_grid:\n",
    "        continue\n",
    "\n",
    "    best_params, best_score = find_best_model_parameters(model, param_grid, X, y)\n",
    "    best_params_and_scores[model_name] = {'Best Parameters': best_params, 'Best Score': best_score}\n",
    "\n",
    "# Print the results\n",
    "for model_name, result in best_params_and_scores.items():\n",
    "    print(f'{model_name}:')\n",
    "    print(f'Best Parameters: {result[\"Best Parameters\"]}')\n",
    "    print(f'Best Score: {result[\"Best Score\"]}\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c015a31a5187d934"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![img.png](img.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "725c126c120b8c05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We leave here a print of the before of the parameters of the models. The after you can check in the code above:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d66f69db8e35026"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![before.png](before.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc00a100f90f07f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion <a id=\"Conclusion\"></a>\n",
    "[Back to index](#Index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10d4160cd6468218"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conclusioning the conlusion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec90c5b68fc411bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
